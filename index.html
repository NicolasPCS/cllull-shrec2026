<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="SHREC 2026: Reconstruction of High-Frequency Geometry in Synthetic Heritage">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="The dataset is generated using a novel procedural pipeline that combines mesh sculpting with semantic vertex annotation, i.e., our ground truth includes per-vertex semantic metadata.">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="SHREC, dataset, cultural, heritage, machine learning, computer vision, AI">
  <!-- TODO: List all authors -->
  <meta name="author" content="Cristián Llull, Iván Sipirán, Nelson Baloian, Francisca Gil">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="Shape Vision Lab">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="SHREC 2026: Reconstruction of High-Frequency Geometry in Synthetic Heritage">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="The dataset is generated using a novel procedural pipeline that combines mesh sculpting with semantic vertex annotation, i.e., our ground truth includes per-vertex semantic metadata.">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://shapevision.dcc.uchile.cl/cllull-shrec2026/">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="PAPER_TITLE - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="Cristián Llull">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@ShapeVisionLab">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@ShapeVisionLab">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="SHREC 2026: Reconstruction of High-Frequency Geometry in Synthetic Heritage">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="The dataset is generated using a novel procedural pipeline that combines mesh sculpting with semantic vertex annotation, i.e., our ground truth includes per-vertex semantic metadata.">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="PAPER_TITLE">
  <meta name="citation_author" content="FIRST_AUTHOR_LAST, FIRST_AUTHOR_FIRST">
  <meta name="citation_author" content="SECOND_AUTHOR_LAST, SECOND_AUTHOR_FIRST">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>SHREC 2026: Reconstruction of High-Frequency Geometry in Synthetic Heritage</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/Icon.png">
  <link rel="apple-touch-icon" href="static/images/Icon.png">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "SHREC 2026: Reconstruction of High-Frequency Geometry",
    "description": "Official track page for SHREC 2026: Reconstruction of High-Frequency Geometry.",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "Shape Vision Lab",
    "url": "https://shapevision.dcc.uchile.cl/",
    "logo": "https://YOUR_DOMAIN.com/static/images/Icon.png",
    "sameAs": [
      "https://x.com/ShapeVisionLab",
      "https://github.com/NicolasPCS"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- More Works Dropdown -->
  <div class="more-works-container">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Our Lab">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>More Works from Our Lab</h4>
        <button class="close-btn" onclick="toggleMoreWorks()">
          <i class="fas fa-times"></i>
        </button>
      </div>
      <div class="works-list">
        <!-- TODO: Replace with your lab's related works -->
        <a href="https://www.ivan-sipiran.com/shrec2021.html" class="work-item" target="_blank">
          <div class="work-info">
            <!-- TODO: Replace with actual paper title -->
            <h5>SHREC 2021: Retrieval of Cultural Heritage Objects</h5>
            <!-- TODO: Replace with brief description -->
            <p>The dataset consists of 938 objects classified into eight categories: jar, pitcher, bowl, figurine, basin, pot, plate, and vase.</p>
            <!-- TODO: Replace with venue and year -->
            <span class="work-venue">SHREC 2021: Retrieval of Cultural Heritage Objects</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <!-- TODO: Add more related works or remove extra items -->
        <!-- <a href="https://arxiv.org/abs/PAPER_ID_2" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 2</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://arxiv.org/abs/PAPER_ID_3" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 3</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a> -->
      </div>
    </div>
  </div>

  <!-- Institutional Top Banner -->
  <section class="institutional-banner">
    <div class="container is-max-desktop banner-content">

      <a href="https://shapevision.dcc.uchile.cl/" 
        target="_blank" 
        rel="noopener noreferrer"
        class="banner-link">

        <div class="banner-left">
          <img src="static/images/Icon.png" 
              alt="ShapeVision Lab Logo" 
              class="nvidia-logo">
        </div>

        <div class="banner-divider"></div>

        <div class="banner-right">
          <span class="lab-name">Shape Vision Lab</span>
        </div>

      </a>

    </div>
  </section>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- TODO: Replace with your paper title -->
            <h1 class="title is-1 publication-title">SHREC 2026: Reconstruction of High-Frequency Geometry in Synthetic Heritage</h1>
            <div class="is-size-5 publication-authors">
              <!-- TODO: Replace with your paper authors and their personal links -->
              <span class="author-block">
                <a href="https://users.dcc.uchile.cl/~cllull/" target="_blank">Cristián Llull</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="https://www.ivan-sipiran.com/index.html" target="_blank">Iván Sipirán</a><sup></sup>,</span>
                  <span class="author-block">
                    <a href="#" target="_blank">Nelson Baloian</a>,
                  </span>
                  <span class="author-block">
                    <a href="#" target="_blank">Francisca Gil</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <!-- TODO: Replace with your institution and conference/journal info -->
                    <span class="author-block">
                      Department of Computer Science - University of Chile</br>
                      CENIA
                    </span>
                    <!-- TODO: Remove this line if no equal contribution -->
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- TODO: Update with your arXiv paper ID -->
                      <span class="link-block">
                        <a href="static/pdfs/SHREC_2026_Proposal.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Proposal</span>
                      </a>
                      </span>

                      <span class="link-block">
                        <a href="https://kaggle.com/datasets/bb8a21d706218ec70737383352dd833e75139d083c68d6c4c93f72457fe0cd43" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fab fa-kaggle"></i>
                        </span>
                        <span>Dataset</span>
                      </a>
                      </span>

                    </div>
                  </div>


                  <!-- TODO: Replace with your GitHub repository URL -->
                  <!-- <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->

                <!-- TODO: Update with your arXiv paper ID -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!--------------------------------------------------------------------------------------------->
<!--------------------------------- HERE STARTS OUR CONTENT ----------------------------------->
<!--------------------------------------------------------------------------------------------->

<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- TODO: Replace with your teaser video -->
      <!-- <video poster="" id="tree" autoplay controls muted loop height="100%" preload="metadata">
        <source src="static/videos/banner_video.mp4" type="video/mp4">
      </video> -->
      <!-- Teaser image -->
      
      <div class="teaser-image-wrapper" align="middle">
        <img 
          src="static/images/Example_Dataset_Arrows.png" 
          alt="Teaser visualization of the project"
          class="teaser-image"
          loading="lazy"
          width="900"
          >
          <h2 class="subtitle has-text-centered">
        Teaser of the four different object versions: normal, large, realistic and wide, with their derivatives:
        cone, cylinder, sphere, egg, pyramid and package.
          </h2>
      </div>

      <!-- <div class="teaser-image-wrapper">
        <img 
          src="static/images/image_gray_scale.png" 
          alt="Teaser visualization of the project"
          class="teaser-image"
          loading="lazy"
          width="300"
        >
        <img 
          src="static/images/frame_042_normal.png" 
          alt="Teaser visualization of the project"
          class="teaser-image"
          loading="lazy"
          width="300"
        >
        <img 
          src="static/images/frame_042_large.png" 
          alt="Teaser visualization of the project"
          class="teaser-image"
          loading="lazy"
          width="300"
        >
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        &nbsp;
        <img 
          src="static/images/frame_042_realistic.png" 
          alt="Teaser visualization of the project"
          class="teaser-image"
          loading="lazy"
          width="300"
        >
        <img 
          src="static/images/frame_042_wide.png" 
          alt="Teaser visualization of the project"
          class="teaser-image"
          loading="lazy"
          width="300"
        > -->
        
      <!-- TODO: Replace with your video description -->
      <!-- <h2 class="subtitle has-text-centered">
        Dataset construction: from one image, take its illumination information and get 4 different objects: normal, large, realistic and wide.
      </h2> -->
    </div>
	
	<div class="hero-body">
      <!-- TODO: Replace with your teaser video -->
      <!-- <video poster="" id="tree" autoplay controls muted loop height="100%" preload="metadata">
        <source src="static/videos/banner_video.mp4" type="video/mp4">
      </video> -->
      <!-- Teaser image -->
      <div class="teaser-image-wrapper" align="middle">
		<img 
          src="static/images/Renderings_1.png" 
          alt="Teaser visualization of the project"
          class="teaser-image"
		  align="middle"
          loading="lazy"
		  width="900"
        >
      </div>
      <!-- TODO: Replace with your video description -->
      <h2 class="subtitle has-text-centered">
        Rendering samples for the realistic version. Participants will be provided with 90 renderings similar to these for reconstructing each object.
      </h2>
    </div>
	
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Cultural heritage artifacts are often defined not by their global shape, but by fine-grained surface details—engravings,
            erosion patterns and reliefs. Standard 3D metrics often fail to capture these high-frequency nuances. 
            <strong>SHREC 2026: High-Frequency Geometry</strong> challenges researchers to <strong>reconstruct</strong> detailed
            3D meshes from multi-view synthetic renderings.
          </p>
          <p>
            We introduce a novel procedurally generated dataset of sculpted stone artifacts with feature-aware ground truth. Key
            features of this track include:
          </p>
          <ul>
            <li><strong>Task:</strong> 3D reconstruction based on localized surface features, from 90 high-quality synthetic
              renderings per object.</li>
            <li><strong>Metric:</strong> A "Semantic Weighting Scheme" prioritizing semantically significant features (e.g., corners,
              reliefs) over flat surfaces.</li>
            <li><strong>Replicability:</strong> Our procedural pipeline allows for full reproducibility. We align with the
              <a href="http://www.replicabilitystamp.org/" target="_blank">Graphics Replicability Stamp Initiative</a>.</li>
            <li><strong>Publication:</strong> All results will be compiled into a joint paper to be submitted to <em>Computers &
              Graphics</em> upon acceptance.</li>
          </ul>
          <p>
          This track is designed to challenge and evaluate the ability of state-of-the-art algorithms to capture high-frequency
          geometric details critical to heritage documentation and analysis.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
	   <h2 class="title is-3">Dataset Samples</h2><br/>Participants will be provided with 90 rendering captures around the generated objects. Here are some captures for the dataset.
        <!-- TODO: Replace with your research result images -->
        <img src="static/images/frame_042_realistic.png" alt="First research result visualization" loading="lazy"/>
        <!-- TODO: Replace with description of this result -->
        <h2 class="subtitle has-text-centered">
          Rendering for object 0001, realistic version.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/frame_042_large.png" alt="Second research result visualization" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Rendering for object 0001, large version.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/frame_042_normal.png" alt="Third research result visualization" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Rendering for object 0001, normal version.
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/frame_042_wide.png" alt="Fourth research result visualization" loading="lazy"/>
      <h2 class="subtitle has-text-centered">
        Rendering for object 0001, wide version.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->


<!-- Track -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="content has-text-justified">
        
        <h2 class="title is-3">The Task & Dataset</h2>
        
        <h3 class="title is-4">Goal</h3>
        <p>
          Participants are provided with <strong>90 high-quality 2D renderings</strong> per object, simulating a
          realistic capture setup (physically based materials, dual-sun lighting, HDRI maps). 
          The goal is to <strong>reconstruct the original 3D object</strong> from these images. While researchers
          may employ any reconstruction method (Photogrammetry, NeRF, Gaussian Splatting, etc.), the challenge
          emphasizes the <strong>geometric fidelity of surface details</strong> (engravings and reliefs).
        </p>

        <h3 class="title is-4">Dataset Characteristics</h3>
        <p>
          The dataset consists of procedurally sculpted meshes derived from a canonical cube. 
        </p>
        <ul>
            <li><strong>Input:</strong> 90 PNG images (1920×1080) per object.</li>
            <li><strong>Materials:</strong> Approximated diffuse stone (high roughness, low metallicity).</li>
            <li><strong>Camera Poses:</strong> We provide full camera intrinsics and extrinsics in COLMAP format for every image.</li> 
        </ul>

        <h3 class="title is-4">Geometric Deformations (Derivatives)</h3>
        <p>
          To test the robustness of reconstruction algorithms across different topologies, our dataset extends beyond the canonical cube. 
          We apply a novel deformation method to the four base styles (Normal, Large, Realistic, Wide), resulting in <strong>6 geometric derivatives</strong> for each style.
        </p>
        <p>
          They are complex 3D shapes morphed into the topological semblance of:
          <strong>Cone, Cylinder, Egg, Package, Pyramid and Sphere</strong>.
          <!-- TODO: Insert images instead of just the list items -->
        </p>

        <h3 class="title is-4">Evaluation: Semantic Weighting</h3>
        <p>
          We utilize a novel <strong>Semantic Weighting Scheme</strong> where reconstruction errors are weighted based on
          vertex importance in the ground truth:
        </p>
        <div class="content is-centered">
            <table class="table is-bordered" style="margin: 0 auto;">
                <tr>
                    <th>Category</th>
                    <th>Importance</th>
                    <th>Description</th>
                </tr>
                <tr>
                    <td>Sculpted Reliefs</td>
                    <td>High</td>
                    <td>Artistic/historical surface content.</td>
                </tr>
                <tr>
                    <td>Corners</td>
                    <td>High</td>
                    <td>Structural integrity.</td>
                </tr>
                <tr>
                    <td>Edges</td>
                    <td>Medium</td>
                    <td>Sharp transitions.</td>
                </tr>
                <tr>
                    <td>Flat Faces</td>
                    <td>Low</td>
                    <td>Baseline geometry.</td>
                </tr>
            </table>
        </div>
        <br>
        <div class="columns is-centered">
            <div class="column has-text-centered">
                 <img src="static/images/Weights.png" alt="Semantic Weights" style="max-width: 400px;">
                 <p class="is-size-7">Visualization of per-vertex semantic weights.</p>
            </div>
        </div>
        This track does not use a query set. Participants will reconstruct 3D models from the provided multi-view renderings,
        and submissions will be evaluated against ground-truth meshes with annotated data.
      </div>
    </div>
  </div>
</section>
		

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="content has-text-justified">
          <h2 class="title is-3">Dataset Reproducibility</h2>

          We take an image and sculpt the content into a 3D mesh. After that, we render 90 images
          in Blender with realistic conditions. 

          <div class="columns is-centered is-vcentered">
            <div class="column is-8">
              <div class="teaser-image-wrapper" align="middle">
                <img src="static/images/image_gray_scale.png" alt="Image gray scale" loading="lazy" width=300/><br/>
                <p class="is-size-7">Extract illumination information and use it as height for the mesh.</p>
              </div>
            </div>
          </div>

          <div class="columns is-centered is-vcentered">
            <div class="column is-8">
              <div class="teaser-image-wrapper" align="middle">
               <img src="static/images/camera_poses.png" alt="Teaser visualization of the project" loading="lazy" width=300/><br/>
               <p class="is-size-7">90 camera poses around the object.</p>
              </div>
            </div>
          </div>

          <div class="columns is-centered is-vcentered">
           <div class="column is-10">

             <div class="teaser-image-wrapper" align="middle">
                <img src="static/images/Renderings_1.png" alt="Teaser visualization of the project" loading="lazy" width=400/>
                <img src="static/images/Renderings_2.png" alt="Teaser visualization of the project" loading="lazy" width=400/>
                <img src="static/images/Renderings_3.png" alt="Teaser visualization of the project" loading="lazy" width=400/>
                <p class="is-size-7">Samples of image renderings provided to participants.</p>
             </div>
           </div>
          </div>
          <div class="content has-text-justified">
            <strong>We provide these renderings</strong>, which practitioners
            should use to reconstruct the 3D objects. We will collect the 3D objects and
            evaluate the quality using a Feature-Aware Weighted Metric (Weighted Chamfer Distance).
          </div>

          <div class="columns is-centered is-vcentered">
             <div class="column is-8">
                <div class="teaser-image-wrapper" align="middle">
                  <img src="static/images/Extract_back_add_texture.png" alt="Teaser visualization of the project" loading="lazy" width=300/><br/>
                   <p class="is-size-7">Extraction of Background.</p>
                </div>
              </div>
            </div>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered">Registration</h2>
        <div class="content has-text-justified">
          <p>
            To participate in this track, please register by sending an email to <a href="mailto:cllull@dcc.uchile.cl">cllull@dcc.uchile.cl</a>. 
            Please include the name of your team members and your institution. Registered participants will receive updates regarding the dataset and submission guidelines.
          </p>
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered">Schedule</h2>
        <div class="content">
          <table class="table is-fullwidth is-striped">
            <thead>
              <tr>
                <th>Date</th>
                <th>Event</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>January 12, 2026</strong></td>
                <td>Track begins / Dataset Release</td>
              </tr>
              <tr>
                <td><strong>March 15, 2026</strong></td>
                <td>Registration Deadline (Recommended)</td>
              </tr>
              <tr>
                <td><strong>April 3, 2026</strong></td>
                <td><strong>Submission Deadline for Reconstruction Results</strong></td>
              </tr>
              <tr>
                <td><strong>April 4-12, 2026</strong></td>
                <td><strong>Evaluation and Results Processing</strong></td>
              </tr>
              <tr>
                <td><strong>April 20, 2026</strong></td>
                <td>Submission of full paper to SHREC</td>
              </tr>
              <tr>
                <td><strong>May 25, 2026:</strong></td>
                <td>First review done, notification of paper acceptance</td>
              </tr>
              <tr>
                <td><strong>July 3, 2026:</strong></td>
                <td>Second stage of reviews complete, decision on acceptance, rejection, or acceptance as short paper.</td>
              </tr>
              <tr>
                <td><strong>July 30, 2026:</strong></td>
                <td>Final decision on acceptance or rejection.</td>
              </tr>
              <tr>
                <td><strong>Sept 3-4, 2026</strong></td>
                <td>Presentation at Eurographics 2026 (3DOR)</td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>
    </div>

  </div>
</section>
<!--
<br>•  <strong>January 9, 2026:</strong> Submission deadline for track proposals.
<br>•  <strong>January 12, 2026:</strong> Notification of acceptance of track proposals.
<br>•  <strong>January 20 to March 30, 2026:</strong> Accepting 3D reconstruction submissions.
<br>•  <strong>March 30 to April 10, 2026:</strong> Evaluation of 3D reconstructions and article elaboration.
<br>•  <strong>April 20, 2026:</strong> Submission deadline for full papers for review.
<br>•  <strong>May 25, 2026:</strong> First review done, first stage decision on acceptance or rejection.
<br>•  <strong>June 19, 2026:</strong> First revision due.
<br>•  <strong>July 3, 2026:</strong> Second stage of reviews complete, decision on acceptance, rejection, or acceptance as short paper.
<br>•  <strong>July 20, 2026:</strong> Final version submission.
<br>•  <strong>July 30, 2026:</strong> Final decision on acceptance or rejection.
<br>•  <strong>September 2026:</strong> Publication online in Computers & Graphics journal.
<br>•  <strong>September 3-4, 2026:</strong> Presentation at the Eurographics 2026 Symposium on 3D Object Retrieval.
-->

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="content has-text-justified">
        <h2 class="title is-3">Submission</h2>
        <div class="content has-text-justified">
          <p>
             Please, upload the dataset to any public repository (e.g., Google Drive, Dropbox, etc.) and share the link with us via email.
             <br/>
             The submission email address is
              <strong><a href="mailto:cllull@dcc.uchile.cl">cllull@dcc.uchile.cl</a></strong>.
             <br/><br/>
             If you have problems uploading large files, please contact us via email. Also, if you have problems with time, please contact us before the submission deadline (you may consider uploading an MD5 file).
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">Contact</h2>
        <!--<button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
        -->
      </div> <!--
  <pre id="bibtex-code"><code>@article{YourPaperKey2024,
  title={Your Paper Title Here},
  author={First Author and Second Author and Third Author},
  journal={Conference/Journal Name},
  year={2024},
  url={https://your-domain.com/your-project-page}
}</code></pre> -->
    <pre id="bibtex-code"><code>
      • Cristián Llull: cllull@dcc.uchile.cl
      • Iván Sipirán: isipiran@dcc.uchile.cl
      • Nelson Baloian: nbaloian@dcc.uchile.cl
      • Francisca Gil: francisca.gil@cenia.cl
    </code></pre>
    </div>
</section>
<!--End BibTex citation -->



  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This project is part of ongoing research conducted at the <a href="https://shapevision.dcc.uchile.cl/" target="_blank">Shape Vision Lab</a>, focusing on 3D vision, shape analysis, and geometry-aware machine learning.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
