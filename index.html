<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="SHREC 2026: Retrieval of High-Frequency Geometry in Synthetic Heritage">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="The dataset is generated using a novel procedural pipeline that combines mesh sculpting with semantic vertex annotation, i.e., our ground truth includes per-vertex semantic metadata.">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="SHREC, dataset, cultural, heritage, machine learning, computer vision, AI">
  <!-- TODO: List all authors -->
  <meta name="author" content="Cristián Llull, Iván Sipirán, Nelson Baloian, Francisca Gil">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="Shape Vision Lab">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="SHREC 2026: Retrieval of High-Frequency Geometry in Synthetic Heritage">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="The dataset is generated using a novel procedural pipeline that combines mesh sculpting with semantic vertex annotation, i.e., our ground truth includes per-vertex semantic metadata.">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://shapevision.dcc.uchile.cl/cllull-shrec2026/">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="PAPER_TITLE - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="FIRST_AUTHOR_NAME">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@ShapeVisionLab">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@ShapeVisionLab">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="SHREC 2026: Retrieval of High-Frequency Geometry in Synthetic Heritage">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="The dataset is generated using a novel procedural pipeline that combines mesh sculpting with semantic vertex annotation, i.e., our ground truth includes per-vertex semantic metadata.">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="PAPER_TITLE">
  <meta name="citation_author" content="FIRST_AUTHOR_LAST, FIRST_AUTHOR_FIRST">
  <meta name="citation_author" content="SECOND_AUTHOR_LAST, SECOND_AUTHOR_FIRST">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>SHREC 2026: Retrieval of High-Frequency Geometry in Synthetic Heritage</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/Icon.png">
  <link rel="apple-touch-icon" href="static/images/Icon.png">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "Shape Vision Lab",
    "url": "https://shapevision.dcc.uchile.cl/",
    "logo": "https://YOUR_DOMAIN.com/static/images/Icon.png",
    "sameAs": [
      "https://x.com/ShapeVisionLab",
      "https://github.com/NicolasPCS"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- More Works Dropdown -->
  <div class="more-works-container">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Our Lab">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>More Works from Our Lab</h4>
        <button class="close-btn" onclick="toggleMoreWorks()">
          <i class="fas fa-times"></i>
        </button>
      </div>
      <div class="works-list">
        <!-- TODO: Replace with your lab's related works -->
        <a href="https://www.ivan-sipiran.com/shrec2021.html" class="work-item" target="_blank">
          <div class="work-info">
            <!-- TODO: Replace with actual paper title -->
            <h5>SHREC 2021: Retrieval of Cultural Heritage Objects</h5>
            <!-- TODO: Replace with brief description -->
            <p>The dataset consists of 938 objects classified into eight categories: jar, pitcher, bowl, figurine, basin, pot, plate, and vase.</p>
            <!-- TODO: Replace with venue and year -->
            <span class="work-venue">SHREC 2021: Retrieval of Cultural Heritage Objects</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <!-- TODO: Add more related works or remove extra items -->
        <!-- <a href="https://arxiv.org/abs/PAPER_ID_2" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 2</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://arxiv.org/abs/PAPER_ID_3" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 3</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a> -->
      </div>
    </div>
  </div>

  <!-- Institutional Top Banner -->
  <section class="institutional-banner">
    <div class="container is-max-desktop banner-content">

      <a href="https://shapevision.dcc.uchile.cl/" 
        target="_blank" 
        rel="noopener noreferrer"
        class="banner-link">

        <div class="banner-left">
          <img src="static/images/Icon.png" 
              alt="ShapeVision Lab Logo" 
              class="nvidia-logo">
        </div>

        <div class="banner-divider"></div>

        <div class="banner-right">
          <span class="lab-name">Shape Vision Lab</span>
        </div>

      </a>

    </div>
  </section>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- TODO: Replace with your paper title -->
            <h1 class="title is-1 publication-title">SHREC 2026: Retrieval of High-Frequency Geometry in Synthetic Heritage</h1>
            <div class="is-size-5 publication-authors">
              <!-- TODO: Replace with your paper authors and their personal links -->
              <span class="author-block">
                <a href="https://users.dcc.uchile.cl/~cllull/" target="_blank">Cristián Llull</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="https://www.ivan-sipiran.com/index.html" target="_blank">Iván Sipirán</a><sup></sup>,</span>
                  <span class="author-block">
                    <a href="#" target="_blank">Nelson Baloian</a>,
                  </span>
                  <span class="author-block">
                    <a href="#" target="_blank">Francisca Gil</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <!-- TODO: Replace with your institution and conference/journal info -->
                    <span class="author-block">Department of Computer Science - University of Chile, CENIA<br>SHREC 2026: Retrieval of High-Frequency Geometry in Synthetic Heritage</span>
                    <!-- TODO: Remove this line if no equal contribution -->
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- TODO: Update with your arXiv paper ID -->
                      <span class="link-block">
                        <a href="static/pdfs/SHREC_2026_Proposal.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Proposal</span>
                      </a>
                    </span>

                  <!-- TODO: Replace with your GitHub repository URL -->
                  <!-- <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->

                <!-- TODO: Update with your arXiv paper ID -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!--------------------------------------------------------------------------------------------->
<!--------------------------------- HERE STARTS OUR CONTENT ----------------------------------->
<!--------------------------------------------------------------------------------------------->

<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- TODO: Replace with your teaser video -->
      <!-- <video poster="" id="tree" autoplay controls muted loop height="100%" preload="metadata">
        <source src="static/videos/banner_video.mp4" type="video/mp4">
      </video> -->
      <!-- Teaser image -->
      <div class="teaser-image-wrapper">
        <img 
          src="static/images/image_gray_scale.png" 
          alt="Teaser visualization of the project"
          class="teaser-image"
          loading="lazy"
        >
      </div>
      <!-- TODO: Replace with your video description -->
      <h2 class="subtitle has-text-centered">
        Convert the original image to grayscale, then scale.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- TODO: Replace with your paper abstract -->
          <p>
            This track aims to shift the focus of 3D retrieval from global shape matching to the recognition of fine-grained, localized surface details—such as engravings, erosion patterns and reliefs, which are often the defining features of cultural heritage artifacts (e.g., armenian Khachkars). Key elements of the proposal:

<br>• <strong>Task:</strong> 3D reconstruction and retrieval based on localized surface features from multi-view synthetic renderings.
<br>• <strong>Novel Dataset:</strong> A procedurally generated, semantically annotated synthetic dataset of sculpted stone artifacts, providing full control and a feature-aware ground truth with per-vertex semantic categories (e.g., corners, edges, sculpted reliefs).
<br>• <strong>Evaluation:</strong> A novel "Semantic Weighting Scheme" for evaluation, allowing performance metrics to be weighted by the cultural or structural importance of different surface regions.
<br>• <strong>Replicability:</strong> The synthetic pipeline ensures reproducibilty.<br>

This track is designed to challenge and evaluate the ability of state-of-the-art algorithms to capture high-frequency geometric details critical to heritage documentation and analysis.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- TODO: Replace with your research result images -->
        <img src="static/images/frame_042_realistic.png" alt="First research result visualization" loading="lazy"/>
        <!-- TODO: Replace with description of this result -->
        <h2 class="subtitle has-text-centered">
          Renderings for object realistic from image 0001.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/frame_042_large.png" alt="Second research result visualization" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Renderings for object large from image 0001.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/frame_042_normal.png" alt="Third research result visualization" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Renderings for object normal from image 0001.
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/frame_042_wide.png" alt="Fourth research result visualization" loading="lazy"/>
      <h2 class="subtitle has-text-centered">
        Renderings for object wide from image 0001.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/carousel1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/carousel2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/carousel3.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->

<!-- Track -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="content has-text-justified">
        <h2 class="title is-3">The Track</h2>
        <div class="content has-text-justified">
          <p>
            In cultural heritage, the value of an artifact often lies not in its overall shape,
but in its surface details—such as engravings, erosion patterns and reliefs. This
track focuses on 3D analysis to achieve geometric fidelity in 3D reconstruction from
multiple-view images. We introduce a novel challenge focused on retrieving objects
based on localized surface features rather than global structure.
We present a controlled synthetic dataset inspired by the intricate stone reliefs found
in heritage artifacts (such as Khachkars or decorative steles). The dataset consists
of parametrically generated meshes derived from a canonical cube primitive. These
objects are procedurally sculpted to emulate the engraving and relief patterns of
real-world artifacts.
By participating in this track, researchers will test the ability of their algorithms
to reconstruct 3D objects from a synthetic but realistic rendering of Khachkars
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="content has-text-justified">
        <h2 class="title is-3">The Challenge</h2>
        <div class="content has-text-justified">
          <p>
            The challenge is to reconstruct the objects from their 2D renderings. Researchers may employ
any 3D reconstruction methods they find suitable. Evaluation will be performed
using the weighted metric described above.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="content has-text-justified">
        <h2 class="title is-3">The Dataset</h2>
        <div class="content has-text-justified">
          <p>
<strong>The Dataset & Feature-Aware Ground Truth</strong>
<br/>
The dataset is generated using a novel procedural pipeline that combines mesh
sculpting with semantic vertex annotation, i.e., our ground truth includes per-vertex
semantic metadata.<br/><br/>
The reconstruction similarity to the ground truth can be ponderated by using the
weights provided by each category in the per-vertex metadata. We refer to this as
the “Semantic Weighting Scheme.” An initial set of weights is associated with the
following ground truth categories:
<li>Corners: High importance to corner preservation (structural integrity).</li>
<li>Edges: Moderate importance to sharp transitions.</li>
<li>Sculpted Reliefs: Priority given to the artistic/historical surface content.</li>
<li>Flat Faces: Baseline importance.</li>

<br/><br/>
<strong>Dataset Characteristics:</strong>
<br/>
Researchers will be provided with the renderings of the objects to facilitate their
reconstructions.
<li>Materiality: Objects are rendered with physically based materials (high rough-
ness, low metallicity) approximating diffuse stone.</li>
<li>Environment: The rendering uses two suns to create a realistic world scenario
and an HDRI map to enhance realistic illumination reflection.</li>
<li>Resolution: Images will be 1920 × 1080 pixels in PNG format.</li>

<br/><br/>
<strong>Dataset Elaboration</strong><br/>
<image src="static/images/image_gray_scale.png" alt="Teaser visualization of the project" loading="lazy"/><br/>
<image src="static/images/camera_poses.png" alt="Teaser visualization of the project" loading="lazy"/><br/>

<image src="static/images/Renderings_1.png" alt="Teaser visualization of the project" loading="lazy"/><br/>
<image src="static/images/Renderings_2.png" alt="Teaser visualization of the project" loading="lazy"/><br/>
<image src="static/images/Renderings_3.png" alt="Teaser visualization of the project" loading="lazy"/><br/>

<image src="static/images/Extract_back_add_texture.png" alt="Teaser visualization of the project" loading="lazy"/><br/>
We take an image and sculpt the content into a 3D mesh. After that, we render 90 images
in Blender with realistic conditions. We provide this renderings, which practicioners
should use to reconstruct the 3D objects. We will coollect the 3D objects and
evaluate the quality using a Feature-Aware Weighted Metric (Weighted Chamfer Distance).

          </p>
        </div>
      </div>
    </div>
  </div>
</section>







<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <!-- TODO: Replace with your poster PDF -->
      <iframe  src="static/pdfs/SHREC_2026_Proposal.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!-- Important dates -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">SHREC Time Schedule<br/>Important dates</h2>
        <div class="content has-text-justified is-normal">
          <p>
            SHREC Time Schedule

Important dates

    <br>• <strong>January 9, 2026:</strong> Submission deadline for track proposals.
    <br>•  <strong>January 12, 2026:</strong> Notification of acceptance of track proposals.
    <br>• <strong>January 12 to April 20, 2026:</strong> Each track has its own time line.
    <br>•  <strong>April 20, 2026:</strong> Submission deadline for full papers for review.
  <!--
    <br>•  <strong>May 25, 2026:</strong> First review done, first stage decision on acceptance or rejection.
    <br>•  <strong>June 19, 2026:</strong> First revision due.
    <br>•  <strong>July 3, 2026:</strong> Second stage of reviews complete, decision on acceptance, rejection, or acceptance as short paper.
    <br>•  <strong>July 20, 2026:</strong> Final version submission.
    <br>• <strong>July 30, 2026:</strong> Final decision on acceptance or rejection.
    <br>•  <strong>September 2026:</strong> Publication online in Computers & Graphics journal.
    <br>• <strong>September 3-4, 2026:</strong> Presentation at the Eurographics 2026 Symposium on 3D Object Retrieval.
   -->
            
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">Contact</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <!-- <pre id="bibtex-code"><code>@article{YourPaperKey2024,
  title={Your Paper Title Here},
  author={First Author and Second Author and Third Author},
  journal={Conference/Journal Name},
  year={2024},
  url={https://your-domain.com/your-project-page}
}</code></pre> -->
    <pre id="bibtex-code"><code>
      • Cristián Llull: cllull@dcc.uchile.cl
      • Iván Sipirán: isipiran@dcc.uchile.cl
      • Nelson Baloian: nbaloian@dcc.uchile.cl
      • Francisca Gil: francisca.gil@cenia.cl
    </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This project is part of ongoing research conducted at the <a href="https://shapevision.dcc.uchile.cl/" target="_blank">Shape Vision Lab</a>, focusing on 3D vision, shape analysis, and geometry-aware machine learning.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
